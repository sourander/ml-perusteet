# üìù Teht√§v√§t

## Teht√§v√§: Auton hinta

Koulut Linear Regression. K√§yt√§ samaa autodataa aiemmissa teht√§viss√§, mutta t√§ll√§ kertaa ennusta auton hintaa. Koska hinta on tyypillinen ennustettava muuttuja t√§ss√§ datasetiss√§, l√∂yd√§t netist√§ referenssitoteutuksia. Eth√§n kuitenkaan kopioi koodia! Kirjoita itse oma koodi, mink√§ jokaisen rivin merkityksen ymm√§rr√§t.


### Vinkit

#### Pipeline

Mik√§li olet aiemmin k√§ytt√§nyt solu solulta etenev√§√§ vapaamuotoista koodia, kokeile t√§ll√§ kertaa k√§ytt√§√§ `sklearn`-kirjaston `Pipeline`- tai `ColumnTransformer`-luokkia. Tee kaikkesi, jotta koodi on helppolukuista ja helposti kehitett√§viss√§. Ideaalitilanteessa esimerkiksi datan esik√§sittely hoituu omalla pipelinell√§, joka voi n√§ytt√§√§ vaikkapa 

```python
from sklearn.pipeline import Pipeline
from sklearn.base import BaseEstimator, TransformerMixin
from feature_engine import selection as fs

class SlugifyColumns(BaseEstimator, TransformerMixin):
    pass

class Mapper(BaseEstimator, TransformerMixin):
    pass

class SplitGroupType(BaseEstimator, TransformerMixin):
    pass

class Whatchamacallit(BaseEstimator, TransformerMixin):
    pass

pipeline = Pipeline(steps=[
    ('slugify_column_names', SlugifyColumns()),
    ('likert_to_number', Mapper(variables=[TARGET], mappings=LIKERT_MAPPINGS)),
    ('split_group_type', SplitGroupType(variables=GROUP_TYPE_COL)),
    ('drop_columns', fs.DropFeatures(DROP_COLUMNS)),
    ('sex_normalize', Whatchamacallit(variables=["foo"])),
])

df_preprocessed = pipeline.fit_transform(df)
```

Huomaa, ett√§ koska kaikki transformaatiot ovat omia luokkiaan, voit helposti lis√§t√§ niit√§ lis√§√§, ja voit helposti uusiok√§ytt√§√§ niit√§ eri pipelinen osissa. T√§m√§ tekee koodista helposti laajennettavaa ja muokattavaa. Niit√§ voi my√∂s testata. Alla yksinkertainen k√§sikutoinen testi:

```python
sgp_input = pd.DataFrame({
    'foo': [' AB123 4', ' 2 ', 'C3', 'D4AB'],
    'other_column': [1, 2, 3, 4]
})
sgp = SplitGroupType(variables=['foo'])
print(sgp.transform(sgp_input))
```

```cmd title="stdout"
   other_column   foo_letters   foo_numbers
0             1            AB          1234
1             2                           2
2             3             C             3
3             4           DAB             4
```

#### Muiden teht√§vien parantelu

T√§m√§ teht√§v√§ on aiempia todenn√§k√∂isesti helpompi, koska datasetti on sinulle jo entuudestaan tuttu, ja Linear Regression on √§√§rimm√§isen yksinkertainen algoritmi. K√§yt√§ t√§ss√§ voitettua aikaa aiempien skriptien ja oppimisp√§iv√§kirjojen parantamiseen. Kenties huomaat oppineesi jotakin uutta Data-osioon liittyvist√§ videoista, jotka antavat sinulle uusia ideoita datan k√§sittelyyn tai mallin suorituskyvyn arviointiin? 

Kenties huomaat my√∂s, ett√§ parin viikon tauon j√§lkeen luettuvuna sinun oma koodisi vaikuttaa vaikealta. Kenties voit kokeilla parantaa my√∂s sit√§ Pipelinen avulla?

## Teht√§v√§: Kyberviha

Kouluta Logistic Regression -malli, joka ennustaa, onko viesti kybervihaa vai ei. K√§yt√§mme t√§t√§ datasettia: [Digital skills among youth: A dataset from a three-wave longitudinal survey in six European countries](https://www.sciencedirect.com/science/article/pii/S2352340924003652)

Sarakkeita on 862, joten olen opettajan roolissa pureskellut hieman dataa valmiiksi. Jupyter Notebook, jolla data on k√§sitelty, sek√§ k√§sitelty data, l√∂ytyv√§t kumpikin [gh:sourander/ml-perusteet-code](https://github.com/sourander/ml-perusteet-code)-repositoriosta. Polut ovat:

* Notebook: `src/playground/yskills_dataprep.ipynb`
* Data: `data/y_skills/ySKILLS_longitudinal_dataset_teacher_processed.csv`

Tavoitteena on ennustaa `RISK101`-kent√§n arvo muiden piirteiden avulla. `RISK101` on bin√§√§rinen muuttuja, joka kertoo, onko henkil√∂ll√§ riski kohdata kybervihaa (engl. cyberhate). On √§√§rimm√§isen suositeltavaa ladata alkuper√§inen datasetti ja sen kylki√§isen√§ toimitettava `ySKILLS_data_dictionary.xlsx`-tiedosto, joka kertoo, mit√§ kent√§t tarkoittavat. On my√∂s √§√§rimm√§isen suositeltavaa lukea yll√§ mainittu Jupyter Notebook l√§pi. Tulemme k√§sittelem√§√§n aihetta my√∂s live-luennolla.

### Vinkit

#### Kirjastot

Tutustu ainakin seuraaviin importattuihin luokkiin tai metodeihin:

```python
from sklearn.linear_model import SGDClassifier, LogisticRegression
```

Muista my√∂s s√§√§t√§√§ mallin hyperparametreja. Esimerkiksi `SGDClassifier`-luokalla on useita parametreja, jotka vaikuttavat mallin oppimiseen ja suorituskykyyn. Voit k√§ytt√§√§ `GridSearchCV`-luokkaa hyperparametrien arvojen haarukointiin. Kuten aiemminkin, muista dokumentoida oppimisp√§iv√§kirjassasi, mit√§ olet tehnyt ja miksi. Varmista, ett√§ ymm√§rr√§t oman koodisi.

#### Tavoite

Pyri v√§hint√§√§n 75 % tarkkuuteen. Alla classification report, joka on saavutettu `LogisticRegression` luokalla ilman mink√§√§n sortin √§lyk√§st√§ hyperparametrien s√§√§t√∂√§ tai opettajan esik√§sittelem√§n datasetin hiomista.

```
              precision    recall  f1-score   support

         0.0       0.68      0.28      0.39       687
         1.0       0.77      0.95      0.85      1796

    accuracy                           0.76      2483
   macro avg       0.73      0.61      0.62      2483
weighted avg       0.75      0.76      0.73      2483
```

#### P√§iv√§kirjan parantelu

T√§m√§ teht√§v√§ saattaa osoittautua helpommaksi kuin arvasit. Nyt onkin hyv√§ aika ottaa kurssikirjat ja muut l√§hteet k√§siin, ja varmistella, ett√§ oppimip√§iv√§kirjasi faktat ovat tikiss√§. Jos t√∂rm√§√§t v√§itteisiin, joista olet ep√§varma, kyseenalaista oma tekstisi. Etsi l√§hteist√§, onko tosiaankin asia kuten olet kirjoittanut. ==Muista l√§hteviitteet!==
